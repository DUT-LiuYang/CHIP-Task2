# CHIP-Task2
## 团队
DUTNLP.未来数据研究所 Rank 5/97
## 赛题描述
问句匹配是自然语言处理的最基本任务之一，是自动问答、聊天机器人、信息检索、机器翻译等各种自然语言处理任务基础。
问句匹配的主要目的是判断两个问句之间的语义是否等价。
判别标准主要根据主句（即提问者）所蕴含的意图来判断两个语句是否等价，
而不直接判断两个语句是否表达相同的语义。因此，其核心是语句的意图匹配。
由于来源于真实问答语料库，该任务更加接近于智能医疗助手等自然语言处理任务的实际需求。
## 数据集描述
比赛中，数据文本本身都是经过了脱敏的操作，即“所有原始文本信息都被编码成单字ID序列和词语ID序列。”单字包含单个汉字、英文字母、标点及空格等；词语包含切词后的中文词语、英文单词、标点及空格等。单字ID和词语ID存在于两个不同的命名空间，即词语中的单字词或者标点，和单字中的相同字符及相同标点不一定有同一个ID。并且提供了预训练好的词向量。数据集有以下文件：

question_id.csv、word_embedding、char_embedding、train.csv、test.csv。question_id.csv为所有脱敏后的问句和其id，有分词和分字两种形式（包含标点符号）。word_embedding和char_embedding分别为预训练好的词和字的embedding（经过脱敏处理，由一个超过200万条医疗问句构成的语料库训练而成）。train.csv和test.csv分别为训练集和测试集，包含若干对由问题id组成的pair。以label表示问句之间的语义是否相同。若相同，标为1，若不相同，标为0。其中，训练集label已知，测试集label未知。
## 技术总结
我们在比赛中，采用的均是单模型交叉验证再进行融合的策略。对于每个单模型我们均做了10折交叉验证，然后在每一折中选择最好的模型进行融合得到一个单模型的结果。对于不同单模型的结果，我们简单的采用投票法进行融合得到最后的提交结果。

我们最终提交的结果，就来自于不同改进版本的ESIM的融合。
差异性体现在词级、字级、字-词级的输入，以及是否扩充了训练集，随机数种子等
另外我们对相似矩阵的求法做了尝试，有两种结果还不错的方法，一个是传统的点积，一个是绝对值相减，后者的代码详见DecomposableAttention.py

程序的运行可以直接运行ESIM_new.py这个文件，当前的代码是字-词级，可以简单地注释掉词级或者字级来运行不同层次的输入。
当前程序默认的是使用扩充之后的训练集，如果想使用原始训练集，可以将子类中重写的load data删掉，这样就可以调用basemodel中的load data了
当前程序中默认使用的是绝对值相减，dot的代码在soft_attention_alignment函数中，可以通过改变调用的函数决定使用哪一种。

扩充数据集的代码在util.py文件中

总结一下，我们基于ESIM的工作主要有以下几点：
- 相似矩阵的生成方式，单词两两相减的结果的绝对值向量，经过压缩作为相似矩阵。我们也尝试了拼接、双线性、相加等公式，结果都不尽人意。
- 不同level的输入，word、char、word-char
- 软对齐之后，只利用对齐的结果和原向量做相减相乘，不做拼接。这样一定程度上有利于句子中一般单词保持原有的含义。对结果有一点提升，但在最后提交的模型中没有广泛使用。

另外，我们利用等价关系的传递性，扩充了训练集。对word和word-char模型的结果都有提升。
## 改进空间
在比赛中限于时间我们仍有一些思路没有尝试，如：
- 用测试集置信度较高的预测实例做伪标签半监督训练
- 阈值不固定于0.5，而是交叉验证时通过开发集灵活的选择阈值
- 采用Bi-GRU以外的编码器，比如Transformer等
- 利用给定语料预训练语言模型

2018参加了两次文本相似度匹配的竞赛，在弥补了一些遗憾的同时留下了新的遗憾
下次比赛见
